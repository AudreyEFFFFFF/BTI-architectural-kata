# 016 LLM Testability

## Status

- Proposed

## Context

### Questions

- How can we create a testing framework for validating our LLM (tools/technologies)?
- How can we ensure that our LLM is not being biased using a testing framework?
- How can we leverage our LLM metrics (Ref: [015.LLMObservability.md](./adrs/015.LLMObservability.md)) in this testing framework?
- How can we train and/or fine-tune our LLM based on our test results?
- What ground truth data do we need for training / fine-tuning our LLM? Who can provide us with this ground truth data?

## Decision

_Decision ("We will...") and justification (the "why‚Äù)._

## Consequences

_Trade-offs and impact of decision._

