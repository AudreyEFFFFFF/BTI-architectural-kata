# 007 Personal Information Removal

## Status

- Proposed

## Context

Per our [system requirements](../main/problem/Requirements.md), our platform AI must remove any personal, racial, cultural, and lifestyle indicators (PII). 

### Questions

- Should this happen before or after SMART goal format parsing.

- Assumption: The LLM has been trained to be effective at removing this information


## Decision

We will remove personal and identifying information before taking any other steps. Studies have shown (TODO link studies here) that training data can be racially biased and AIs can behave in racially biased ways, so we will remove this information before attempting any parsing of candidates fitness to ensure the most equitable process.

## Consequences

_Trade-offs and impact of decision._

